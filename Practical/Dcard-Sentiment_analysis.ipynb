{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "Sentiment_data = pandas.read_csv(\"SentimentDict.csv\",encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Sentiment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['positive', 'negative', 'not', 'degree-1', 'degree-2', 'degree-3',\n",
       "       'degree-4', 'degree-5', 'degree-6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentiment_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dcard import Dcard\n",
    "import dateutil.parser\n",
    "import csv\n",
    "import pandas\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build positive & negative lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5006\n"
     ]
    }
   ],
   "source": [
    "# print positive len\n",
    "positives_set=set(Sentiment_data[\"positive\"])\n",
    "print(len(positives_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4686\n"
     ]
    }
   ],
   "source": [
    "# print negatives len\n",
    "negatives_set = set(Sentiment_data['negative'])\n",
    "print(len(negatives_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Build negative Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214\n"
     ]
    }
   ],
   "source": [
    "not_set = set(Sentiment_data['not'])\n",
    "print(len(not_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Customized Level Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "112\n",
      "146\n",
      "174\n",
      "186\n",
      "213\n"
     ]
    }
   ],
   "source": [
    "# degree-1 => multiply 1.8\n",
    "degree_dict = {}\n",
    "for word in Sentiment_data['degree-1']:\n",
    "    degree_dict[word] = 1.8\n",
    "print(len(degree_dict))\n",
    "# 69\n",
    "# degree-2 => multiply 1.6\n",
    "for word in Sentiment_data['degree-2']:\n",
    "    degree_dict[word] = 1.6\n",
    "print(len(degree_dict))\n",
    "# 112\n",
    "# degree-3 => multiply 1.4\n",
    "for word in Sentiment_data['degree-3']:\n",
    "    degree_dict[word] = 1.4\n",
    "print(len(degree_dict))\n",
    "# 146\n",
    "# degree-4 => multiply 1.2\n",
    "for word in Sentiment_data['degree-4']:\n",
    "    degree_dict[word] = 1.2\n",
    "print(len(degree_dict))\n",
    "# 174\n",
    "# degree-5 => multiply 1.1\n",
    "for word in Sentiment_data['degree-5']:\n",
    "    degree_dict[word] = 1.1\n",
    "print(len(degree_dict))\n",
    "# 186\n",
    "# degree-6 => multiply 0.9\n",
    "for word in Sentiment_data['degree-6']:\n",
    "    degree_dict[word] = 0.9\n",
    "print(len(degree_dict))\n",
    "# 213"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check negative lexicon\n",
    "def hasOpposite(wordlist):\n",
    "    for word in wordlist:\n",
    "        if word in not_set:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Customized Level word: return value; else: return 1.0\n",
    "def getDegree(wordlist):\n",
    "    degree =1.0\n",
    "    for word in wordlist:\n",
    "        if word in degree_dict:\n",
    "            degree = degree_dict[word]\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "# Get score\n",
    "def analyze (text):\n",
    "    token = list(jieba.cut(text))\n",
    "    #print(token)\n",
    "    sum  = 0 \n",
    "    for word in token:\n",
    "        if word.lower() in positives_set:\n",
    "            sum += 1\n",
    "        elif word.lower() in negatives_set:\n",
    "            sum -= 1\n",
    "    if hasOpposite(token):\n",
    "        sum = - sum\n",
    "    sum = sum * getDegree(token)\n",
    "        \n",
    "    return sum\n",
    "\n",
    "# analyze positive or negative\n",
    "def sentiment_analysis(text):\n",
    "    sentiment = 'normal'\n",
    "    score =  analyze(text)\n",
    "    \n",
    "    #print('emotional score',score)\n",
    "    if score > 0:\n",
    "        sentiment = 'positive'\n",
    "    elif score < 0.0:\n",
    "        sentiment = 'negative'\n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output： negative\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "text = '我很不高興'\n",
    "print('Output：',sentiment_analysis(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get article by Dcard-spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keyword(metas):\n",
    "    return [meta for meta in metas if meta['commentCount'] >= 2]\n",
    "def dcard(forums,text):\n",
    "    URL = \"https://www.dcard.tw/f/dcard/p/\"\n",
    "    dcard = Dcard()  \n",
    "    metas = dcard.forums(forums).get_metas(num=50, callback=keyword)\n",
    "    posts = dcard.posts(metas).get(comments=True, links=False)\n",
    "    last = {'positive' : 0 ,'title':\"\", 'id':\"\" ,'negative':0}\n",
    "    context =\"\"\n",
    "    for post in posts.result():\n",
    "        ans ={'positive':0,'negative':0,'normal':0}\n",
    "        #print(\"Title:\"+post['title'])\n",
    "        \n",
    "        ans[sentiment_analysis(post['content'])]+=1\n",
    "        for comment in post['comments']:\n",
    "            if(not comment['hidden']): # Analyze comment if it's not hidden\n",
    "                ans[sentiment_analysis(comment['content'])]+=1\n",
    "        if text ==\"positive\":\n",
    "            if ans['positive'] >last['positive'] :\n",
    "                last['positive'] = ans['positive']\n",
    "                last['title'] = post['title']\n",
    "                last['id'] = post['id']\n",
    "        else:\n",
    "            if ans['negative'] >last['negative'] :\n",
    "                last['negative'] = ans['negative']\n",
    "                last['title'] = post['title']\n",
    "                last['id'] = post['id']\n",
    "    context += \"Most \"+text+\" response:\" + last['title'] + \"\\n\" + URL + str(last['id'])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    print(dcard(\"fcu\",\"positive\")) #article with the most response in fcu\n",
    "    print(dcard(\"funny\",\"negative\")) #article with the most response in funny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "https://github.com/mathlf2015/text_analysis/tree/master/code/sentiment/sentimentDict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
